{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:15.806374300Z",
     "start_time": "2023-11-28T16:02:15.335407300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=11, micro=4, releaselevel='final', serial=0)\n",
      "Scikit-Learn version:  1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version_info)\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "from packaging import version\n",
    "import sklearn\n",
    "print (\"Scikit-Learn version: \", sklearn.__version__)\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(image_data, axis=False):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "\n",
    "    if not axis:\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.083578300Z",
     "start_time": "2023-11-28T16:02:15.806374300Z"
    }
   },
   "id": "4fe3b7528a2dbfd4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def plot_multi(img,start=0,end=100):\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    for idx, image_data in enumerate(img[start:end]):\n",
    "        plt.subplot(10, 10, idx + 1)\n",
    "        plot_digit(image_data)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.124294300Z",
     "start_time": "2023-11-28T16:02:16.087377100Z"
    }
   },
   "id": "833c8640e88a5765"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_cleaned\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# this is where the datasets are located\n",
    "path = Path() / \"dataset_cleaned\"\n",
    "print(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.124294300Z",
     "start_time": "2023-11-28T16:02:16.087377100Z"
    }
   },
   "id": "99c77253d1e24a01"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# your training datasets\n",
    "# must be cleaned\n",
    "\n",
    "my_data_num = np.load(path / \"digit_data_TrVal_relabeled_v2.npz\")\n",
    "my_data_sym = np.load(path / \"op_data_TrVal_relabeled_v2.npz\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.124294300Z",
     "start_time": "2023-11-28T16:02:16.092200100Z"
    }
   },
   "id": "d570ec7fa5214cdc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def rebase_center(img):\n",
    "    r = 28\n",
    "    c = 28\n",
    "\n",
    "    # each boundary\n",
    "    r_top = r\n",
    "    r_bot = -1\n",
    "    c_left = c\n",
    "    c_right = -1\n",
    "\n",
    "    for n in range(r):\n",
    "        for m in range(c):\n",
    "            \n",
    "            # if the pixel has whatever value\n",
    "            if img[n][m] != 0:\n",
    "                # update the boundary\n",
    "                r_top = min(r_top, n)\n",
    "                r_bot = max(r_bot, n)\n",
    "                c_left = min(c_left, m)\n",
    "                c_right = max(c_right, m)\n",
    "    \n",
    "    # print(r_top,r_bot,c_left,c_right)\n",
    "    \n",
    "    c_len = c_right - c_left + 1\n",
    "    r_len = r_bot - r_top + 1\n",
    "\n",
    "    c_start = int((c - c_len) / 2)\n",
    "    r_start = int((r - r_len) / 2)\n",
    "\n",
    "    # print(c_len,r_len,c_start,r_start)\n",
    "\n",
    "    rebased_data = np.zeros((r,c),dtype=\"float64\")\n",
    "\n",
    "    # rebase into a center\n",
    "    rebased_data[r_start:r_start+r_len, c_start:c_start+c_len] = img[r_top:r_bot+1, c_left:c_right+1]\n",
    "    \n",
    "    return rebased_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.124294300Z",
     "start_time": "2023-11-28T16:02:16.096687600Z"
    }
   },
   "id": "178be626788ba478"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def detect_del_boundary(img, thickness = 4, threshold = 10):\n",
    "    curr = np.reshape(img,(28,28))\n",
    "    \n",
    "    # how much you want to look at\n",
    "    t = thickness\n",
    "    # the threshold\n",
    "    threshold_t = threshold\n",
    "    \n",
    "    for i in range(thickness):\n",
    "        cnt_top = np.count_nonzero(curr[i:i+1,:])\n",
    "        cnt_down = np.count_nonzero(curr[28-i:28-i+1,:])\n",
    "        cnt_left = np.count_nonzero(curr[:,i:i+1])\n",
    "        cnt_right = np.count_nonzero(curr[:,27-i:27-i+1])\n",
    "        \n",
    "        if cnt_top > threshold_t:\n",
    "            curr[0:t,:] = 0.\n",
    "        \n",
    "        if cnt_down > threshold_t:\n",
    "            curr[28-t:28,:] = 0.\n",
    "        \n",
    "        if cnt_left > threshold_t:\n",
    "            curr[:,0:t] = 0.\n",
    "            \n",
    "        if cnt_right > threshold_t:\n",
    "            curr[:,28-t:28] = 0.\n",
    "    \n",
    "    return curr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.124294300Z",
     "start_time": "2023-11-28T16:02:16.101179100Z"
    }
   },
   "id": "2b7ac6c9d93c5709"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def dfs(r,c,img, visited):\n",
    "    st = list()\n",
    "    st.append([r,c])\n",
    "    \n",
    "    cord = [[1,1],[1,0],[1,-1],[0,1],[0,-1],[-1,1],[-1,0],[-1,-1]]\n",
    "    \n",
    "    dot = list()\n",
    "    \n",
    "    while st:\n",
    "        curr = st.pop()\n",
    "        \n",
    "        if visited[curr[0]][curr[1]] == 1.: continue\n",
    "        \n",
    "        dot.append(curr)\n",
    "        visited[curr[0]][curr[1]] = 1.\n",
    "        \n",
    "        for n,m in enumerate(cord):\n",
    "            row = curr[0] + m[0]\n",
    "            col = curr[1] + m[1]\n",
    "            \n",
    "            if 0 <= row < 28 and 0 <= col < 28:\n",
    "                if img[row][col] != 0. and visited[row][col] == 0.:\n",
    "                    st.append([row,col])\n",
    "            \n",
    "    \n",
    "    return dot,visited"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.124294300Z",
     "start_time": "2023-11-28T16:02:16.105612400Z"
    }
   },
   "id": "ea6f37651563abd"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def d_deletion(img, dot_size = 4):\n",
    "    \n",
    "    # to check whether we visited\n",
    "    isVisited = np.full((28,28),0.)\n",
    "    \n",
    "    # dots that needs to be deleted afterwards\n",
    "    dots = list()\n",
    "    \n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if img[i][j] != 0. and not isVisited[i][j]:\n",
    "                dot, isVisited = dfs(i,j,img,isVisited)\n",
    "                \n",
    "                if len(dot) <= dot_size:\n",
    "                    dots.extend(dot)\n",
    "    \n",
    "    \n",
    "        for n,m in enumerate(dots):\n",
    "            img[m[0],m[1]] = 0.\n",
    "    \n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.124294300Z",
     "start_time": "2023-11-28T16:02:16.110131600Z"
    }
   },
   "id": "cd46fea652dec6ff"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def resize(img,size=18):\n",
    "    r = 28\n",
    "    c = 28\n",
    "    \n",
    "    # each boundary\n",
    "    r_top = r\n",
    "    r_bot = -1\n",
    "    c_left = c\n",
    "    c_right = -1\n",
    "    \n",
    "    for n in range(r):\n",
    "        for m in range(c):\n",
    "            \n",
    "            # if the pixel has whatever value\n",
    "            if img[n][m] != 0:\n",
    "                # update the boundary\n",
    "                r_top = min(r_top, n)\n",
    "                r_bot = max(r_bot, n)\n",
    "                c_left = min(c_left, m)\n",
    "                c_right = max(c_right, m)\n",
    "                \n",
    "    row_len = r_bot - r_top + 1\n",
    "    col_len = c_right - c_left + 1\n",
    "    \n",
    "    adjusted_img = img[r_top:r_bot+1,c_left:c_right+1]\n",
    "    \n",
    "    diff = abs(row_len - col_len)\n",
    "    \n",
    "    top_pad = int(diff / 2)\n",
    "    down_pad = int(diff / 2)\n",
    "    \n",
    "    if diff % 2 == 1:\n",
    "        top_pad += 1\n",
    "    \n",
    "    if row_len > col_len:\n",
    "        adjusted_img = np.pad(adjusted_img, pad_width=((0,0),(top_pad,down_pad)), mode=\"constant\")\n",
    "            \n",
    "    else:\n",
    "        adjusted_img = np.pad(adjusted_img, pad_width=((top_pad,down_pad),(0,0)), mode=\"constant\")         \n",
    "        \n",
    "\n",
    "    import cv2\n",
    "    \n",
    "    try:\n",
    "        # using inter_nearest\n",
    "        resized_img = cv2.resize(adjusted_img, dsize=(size,size),interpolation=0)\n",
    "    except:\n",
    "        return img\n",
    "    \n",
    "    resized_img = np.pad(resized_img,int((28 - size)/2),mode=\"constant\")\n",
    "    \n",
    "    return resized_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.147765600Z",
     "start_time": "2023-11-28T16:02:16.114225300Z"
    }
   },
   "id": "3221e2957dad8b9f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def preprocessing(img, rebase=True, b_del=True, d_del=True, re_size=True, one_array=True):\n",
    "    size = np.shape(img)[0]\n",
    "    \n",
    "    # row and column length\n",
    "    r = 28\n",
    "    c = 28\n",
    "    \n",
    "    # reshape to 2-d array(for convenience)\n",
    "    img_preprocessed = np.reshape(img,(size,r,c))\n",
    "    \n",
    "    # rebase\n",
    "    if rebase:\n",
    "        print(\"rebase ongoing\")\n",
    "        \n",
    "        for x in range(size):\n",
    "            img_preprocessed[x] = rebase_center(img_preprocessed[x])\n",
    "        print(\"done!\")\n",
    "    \n",
    "    # border deletion\n",
    "    if b_del:\n",
    "        print(\"border deletion ongoing\")\n",
    "        \n",
    "        for x in range(size):\n",
    "            img_preprocessed[x] = detect_del_boundary(img_preprocessed[x],thic,thres)\n",
    "            \n",
    "        print(\"done!\")\n",
    "    \n",
    "    # dot deletion\n",
    "    if d_del:\n",
    "        print(\"dot deletion ongoing\")\n",
    "        \n",
    "        for x in range(size):\n",
    "            img_preprocessed[x] = d_deletion(img_preprocessed[x],dot_size=siz)\n",
    "            \n",
    "        print(\"done!\")\n",
    "    \n",
    "    # resize\n",
    "    if re_size:\n",
    "        print(\"resize ongoing\")\n",
    "        \n",
    "        for x in range(size):\n",
    "            img_preprocessed[x] = resize(img_preprocessed[x])\n",
    "        \n",
    "        print(\"done!\")\n",
    "    \n",
    "    return np.reshape(img_preprocessed,(size,r*c)) if one_array else np.reshape(img_preprocessed,(size,r,c))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.194635Z",
     "start_time": "2023-11-28T16:02:16.124294300Z"
    }
   },
   "id": "6bb7f7565a85f379"
  },
  {
   "cell_type": "markdown",
   "source": [
    "so we have completed our preprocessing, but we have not actually tested each parameter\n",
    "so here similar to the **gridSearchCV()**, we shall try numerous values to the parameter and get the best one"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "380a34a2e43e464e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "my_data_combine_img = np.concatenate((my_data_num[\"img\"],my_data_sym[\"img\"]),axis=0)\n",
    "my_data_combine_label = np.concatenate((my_data_num[\"label\"],my_data_sym[\"label\"]),axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.341059500Z",
     "start_time": "2023-11-28T16:02:16.132139500Z"
    }
   },
   "id": "3ad9339034999d54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## basic"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0c55798ddb0852e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "random = 42\n",
    "\n",
    "nn_clf = make_pipeline(RobustScaler(), MLPClassifier(random_state=random,solver=\"lbfgs\",max_iter=500))\n",
    "nn_clf_adam = make_pipeline(RobustScaler(), MLPClassifier(random_state=random,solver=\"adam\",max_iter=500))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:16.389475800Z",
     "start_time": "2023-11-28T16:02:16.341059500Z"
    }
   },
   "id": "eefa242dbefc4914"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('robustscaler', RobustScaler()),\n                ('mlpclassifier',\n                 MLPClassifier(max_iter=500, random_state=42, solver='lbfgs'))])",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;robustscaler&#x27;, RobustScaler()),\n                (&#x27;mlpclassifier&#x27;,\n                 MLPClassifier(max_iter=500, random_state=42, solver=&#x27;lbfgs&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;robustscaler&#x27;, RobustScaler()),\n                (&#x27;mlpclassifier&#x27;,\n                 MLPClassifier(max_iter=500, random_state=42, solver=&#x27;lbfgs&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=500, random_state=42, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_clf.fit(my_data_combine_img.reshape(-1,784),my_data_combine_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:02:52.875521300Z",
     "start_time": "2023-11-28T16:02:16.389475800Z"
    }
   },
   "id": "d6e85dcc6f544065"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.65917603, 0.65878179, 0.6620343 ])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# lbfgs\n",
    "\n",
    "cross_val_score(nn_clf, my_data_combine_img.reshape(-1,784), my_data_combine_label, cv=3,n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:03:36.177402400Z",
     "start_time": "2023-11-28T16:02:52.875521300Z"
    }
   },
   "id": "aa434b6adbc1dca1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "test = cross_val_score(nn_clf, my_data_combine_img.reshape(-1,784), my_data_combine_label, cv=3,n_jobs=-1).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:04:19.302874700Z",
     "start_time": "2023-11-28T16:03:36.177402400Z"
    }
   },
   "id": "820ce64bbdb3bba5"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:04:19.307079600Z",
     "start_time": "2023-11-28T16:04:19.302874700Z"
    }
   },
   "id": "492f7544932d30c6"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('robustscaler', RobustScaler()),\n                ('mlpclassifier',\n                 MLPClassifier(max_iter=500, random_state=42))])",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;robustscaler&#x27;, RobustScaler()),\n                (&#x27;mlpclassifier&#x27;,\n                 MLPClassifier(max_iter=500, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;robustscaler&#x27;, RobustScaler()),\n                (&#x27;mlpclassifier&#x27;,\n                 MLPClassifier(max_iter=500, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=500, random_state=42)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adam\n",
    "\n",
    "nn_clf_adam.fit(my_data_combine_img.reshape(-1,784),my_data_combine_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:05:18.895579100Z",
     "start_time": "2023-11-28T16:04:19.307079600Z"
    }
   },
   "id": "cbcb574503f9c45f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.6696235 , 0.66154149, 0.67602996])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nn_clf_adam, my_data_combine_img.reshape(-1,784), my_data_combine_label, cv=3,n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:06:23.878939800Z",
     "start_time": "2023-11-28T16:05:18.895579100Z"
    }
   },
   "id": "697c2ee575781d1f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "adam is slightly better, we shall use that value for now"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71b5dce6639224e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rebase"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4bb2e255deb14b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "rebase has no parameters, we shall just check its **cross_val_score** to check the improvement"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7592de6cc8b729"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebase ongoing\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.79262764, 0.79893554, 0.78553124])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_num_img_rebase = preprocessing(my_data_combine_img,True,False,False,False,True)\n",
    "\n",
    "nn_clf_adam.fit(my_data_num_img_rebase,my_data_combine_label)\n",
    "cross_val_score(nn_clf_adam, my_data_num_img_rebase, my_data_combine_label, cv=3,n_jobs=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:09:17.319152900Z",
     "start_time": "2023-11-28T16:06:23.888588300Z"
    }
   },
   "id": "7e7d992cc9299931"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## border del"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5a93ca0bc1c0701"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "size = my_data_combine_img.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:09:17.319152900Z",
     "start_time": "2023-11-28T16:09:17.319152900Z"
    }
   },
   "id": "8cdae251c2449ac"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result in 3 thickness and 10 threshold: 0.7919377094421448\n",
      "result in 3 thickness and 15 threshold: 0.7930218805440568\n",
      "result in 3 thickness and 20 threshold: 0.7919377094421446\n",
      "result in 4 thickness and 10 threshold: 0.7917077337538604\n",
      "result in 4 thickness and 15 threshold: 0.7898679282475852\n",
      "result in 4 thickness and 20 threshold: 0.7899007819173401\n",
      "result in 5 thickness and 10 threshold: 0.7871739273276824\n",
      "result in 5 thickness and 15 threshold: 0.7900321965963598\n",
      "result in 5 thickness and 20 threshold: 0.7912806360470465\n",
      "best result is 0.7930218805440568 at thickness: 3, and threshold: 15\n"
     ]
    }
   ],
   "source": [
    "thick = [3,4,5]\n",
    "threshold = [10,15,20]\n",
    "\n",
    "best_score = 0\n",
    "best_thick= 0\n",
    "best_threshold= 0\n",
    "\n",
    "my_data_save_0 = my_data_combine_img.copy()\n",
    "\n",
    "for x in range(size):\n",
    "    my_data_save_0[x] = rebase_center(my_data_save_0[x])\n",
    "\n",
    "for i,j in enumerate(thick):\n",
    "    for n,m in enumerate(threshold):\n",
    "        my_data_border = my_data_save_0.copy()\n",
    "        \n",
    "        for x in range(size):\n",
    "            my_data_border[x] = detect_del_boundary(my_data_border[x],j,m)\n",
    "        \n",
    "        my_data_border = my_data_border.reshape(-1,784)\n",
    "        \n",
    "        nn_clf_adam.fit(my_data_border,my_data_combine_label)\n",
    "        score_mean = cross_val_score(nn_clf_adam, my_data_border, my_data_combine_label, cv=3,n_jobs=-1).mean()\n",
    "        \n",
    "        print(f\"result in {j} thickness and {m} threshold: {score_mean}\")\n",
    "        \n",
    "        if score_mean > best_score:\n",
    "            best_score = score_mean\n",
    "            best_thick = j\n",
    "            best_threshold = m\n",
    "\n",
    "print(f\"best result is {best_score} at thickness: {best_thick}, and threshold: {best_threshold}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:33:45.152275200Z",
     "start_time": "2023-11-28T16:09:17.319152900Z"
    }
   },
   "id": "a345ce98f2ef3bbe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## dot deletion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5333e8030502f4db"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result in 2 dot size: 0.7887837571456732\n",
      "result in 3 dot size: 0.7886851961364084\n",
      "result in 4 dot size: 0.7872396346671923\n",
      "result in 5 dot size: 0.790295025954399\n",
      "result in 6 dot size: 0.7882252447598397\n",
      "result in 7 dot size: 0.7853998291609173\n",
      "best result is 0.790295025954399 at dot size: 5\n"
     ]
    }
   ],
   "source": [
    "dot = [2,3,4,5,6,7]\n",
    "\n",
    "best_score = 0\n",
    "best_dot = 0\n",
    "\n",
    "my_data_save_1 = my_data_combine_img.copy()\n",
    "\n",
    "for x in range(size):\n",
    "    my_data_save_1[x] = rebase_center(my_data_save_1[x])\n",
    "    my_data_save_1[x] = detect_del_boundary(my_data_save_1[x],3,15)\n",
    "\n",
    "for i,j in enumerate(dot):\n",
    "    my_data_dot = my_data_save_1.copy()\n",
    "        \n",
    "    for y in range(size):\n",
    "        my_data_dot[y] = d_deletion(my_data_dot[y],j)\n",
    "        \n",
    "    my_data_dot = my_data_dot.reshape(-1,784)\n",
    "        \n",
    "        \n",
    "    nn_clf_adam.fit(my_data_dot,my_data_combine_label)\n",
    "    score_mean = cross_val_score(nn_clf_adam, my_data_dot, my_data_combine_label, cv=3,n_jobs=-1).mean()\n",
    "        \n",
    "    print(f\"result in {j} dot size: {score_mean}\")\n",
    "            \n",
    "    if score_mean > best_score:\n",
    "        best_score = score_mean\n",
    "        best_dot = j\n",
    "        \n",
    "print(f\"best result is {best_score} at dot size: {best_dot}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T16:53:27.631362900Z",
     "start_time": "2023-11-28T16:35:27.822259500Z"
    }
   },
   "id": "79c4ebf9c14f7606"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## resize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd184823131fd617"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result in 16 size: 0.7994940534857745\n",
      "result in 18 size: 0.8046520796372955\n",
      "result in 20 size: 0.8072146658781786\n",
      "best result is 0.8072146658781786 at size: 20\n"
     ]
    }
   ],
   "source": [
    "siz = [16,18,20]\n",
    "\n",
    "my_data_save_2 = my_data_save_1.copy()\n",
    "\n",
    "# for x in range(size):\n",
    "#     my_data_save_2[x] = d_deletion(my_data_save_2[x],)\n",
    "\n",
    "best_score = 0\n",
    "best_size = 0\n",
    "\n",
    "for i,j in enumerate(siz):\n",
    "    my_data_resize = my_data_combine_img.copy()\n",
    "    \n",
    "    for z in range(size):\n",
    "        my_data_resize[z] = resize(my_data_resize[z],size=j)\n",
    "        \n",
    "    my_data_resize = my_data_resize.reshape(-1,784)\n",
    "        \n",
    "    nn_clf_adam.fit(my_data_resize,my_data_combine_label)\n",
    "    score_mean = cross_val_score(nn_clf_adam, my_data_resize, my_data_combine_label, cv=3,n_jobs=-1).mean()\n",
    "        \n",
    "    print(f\"result in {j} size: {score_mean}\")\n",
    "            \n",
    "    if score_mean > best_score:\n",
    "        best_score = score_mean\n",
    "        best_size = j\n",
    "        \n",
    "print(f\"best result is {best_score} at size: {best_size}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:37:20.457718100Z",
     "start_time": "2023-11-28T15:28:04.808009300Z"
    }
   },
   "id": "dff63fd8f4d8d189"
  },
  {
   "cell_type": "markdown",
   "source": [
    "as the size of **resize()** affects the score as it gets larger, but we may need to match with the mnist. let's check mnist's size and match them"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b85c3068d0f5a9b"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "openml = fetch_openml('mnist_784', as_frame=False,parser=\"auto\")\n",
    "mnist = openml\n",
    "\n",
    "mnist_img = mnist.data\n",
    "mnist_label = mnist.target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:43:58.853096700Z",
     "start_time": "2023-11-28T15:43:56.399002300Z"
    }
   },
   "id": "81bbf976f498bc74"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(mnist_img[10],True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:44:19.400604Z",
     "start_time": "2023-11-28T15:44:19.317057200Z"
    }
   },
   "id": "a933b4fab7d364ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "about 20, so 20 shall do"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59409c0e8622e0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## == handmade test from here =="
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de2f772121beed77"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "test_data = np.load(\"handmade_test.npz\")\n",
    "\n",
    "test_data_img = test_data[\"img\"]\n",
    "test_data_label = test_data[\"label\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T08:42:12.150159100Z",
     "start_time": "2023-11-27T08:42:12.129155900Z"
    }
   },
   "id": "6ea6049d715e2fca"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_img.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T08:42:28.863934200Z",
     "start_time": "2023-11-27T08:42:28.833572900Z"
    }
   },
   "id": "593ab6d2476eab51"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('int32')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_label.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T08:42:38.370063300Z",
     "start_time": "2023-11-27T08:42:38.350156300Z"
    }
   },
   "id": "ea57cad1f7a2084"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 28, 28)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T08:53:29.360007100Z",
     "start_time": "2023-11-27T08:53:29.316500600Z"
    }
   },
   "id": "93b6d31533437fd6"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1,parser=\"auto\")\n",
    "mnist_images = (mnist.data.to_numpy() / 255).round()\n",
    "mnist_labels = mnist.target.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:01:55.710272Z",
     "start_time": "2023-11-27T09:01:52.974421Z"
    }
   },
   "id": "6d40c81efcc62351"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_images.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:01:56.443284900Z",
     "start_time": "2023-11-27T09:01:56.417867900Z"
    }
   },
   "id": "78b2a53b70f5e645"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "(70000, 784)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_images.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:03:56.898809500Z",
     "start_time": "2023-11-27T09:03:56.874294300Z"
    }
   },
   "id": "49bc021edb811830"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['5', '0', '4', ..., '4', '5', '6'], dtype='<U1')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_labels.astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:01:57.004336600Z",
     "start_time": "2023-11-27T09:01:56.973506900Z"
    }
   },
   "id": "87f93a7b3f9c853f"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_clf = MLPClassifier(random_state=42).fit(mnist_images,mnist_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:02:58.495134700Z",
     "start_time": "2023-11-27T09:01:59.781778100Z"
    }
   },
   "id": "f7918e21dec736df"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 784)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_img = np.reshape(test_data_img,(-1,784))\n",
    "test_data_img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:04:08.411771600Z",
     "start_time": "2023-11-27T09:04:08.386481Z"
    }
   },
   "id": "bae1c382d2619d9d"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '1', '2',\n       '3', '4', '5', '6', '7', '8', '9', '0', '1', '2', '3', '4', '5',\n       '6', '7', '8', '9', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n       '9', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '1',\n       '2', '3', '4', '5', '6', '7', '8', '9', '0', '1', '2', '3', '4',\n       '5', '6', '7', '8', '9', '0', '1', '2', '3', '4', '5', '6', '7',\n       '8', '9', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0',\n       '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U11')"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_label.astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:03:01.594775900Z",
     "start_time": "2023-11-27T09:03:01.554990900Z"
    }
   },
   "id": "1f32fda5e68f6476"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 78400 features, but MLPClassifier is expecting 784 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[63], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m nn_clf\u001B[38;5;241m.\u001B[39mscore(test_data_img\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m),test_data_label)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:705\u001B[0m, in \u001B[0;36mClassifierMixin.score\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    680\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001B[39;00m\n\u001B[0;32m    682\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    701\u001B[0m \u001B[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001B[39;00m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n\u001B[1;32m--> 705\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m accuracy_score(y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(X), sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1160\u001B[0m, in \u001B[0;36mMLPClassifier.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001B[39;00m\n\u001B[0;32m   1148\u001B[0m \n\u001B[0;32m   1149\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1157\u001B[0m \u001B[38;5;124;03m    The predicted classes.\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1159\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m-> 1160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict(X)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1164\u001B[0m, in \u001B[0;36mMLPClassifier._predict\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m   1162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1163\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1164\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pass_fast(X, check_input\u001B[38;5;241m=\u001B[39mcheck_input)\n\u001B[0;32m   1166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1167\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m y_pred\u001B[38;5;241m.\u001B[39mravel()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:207\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict using the trained model\u001B[39;00m\n\u001B[0;32m    189\u001B[0m \n\u001B[0;32m    190\u001B[0m \u001B[38;5;124;03mThis is the same as _forward_pass but does not record the activations\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;124;03m    The decision function of the samples for each class in the model.\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_input:\n\u001B[1;32m--> 207\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, accept_sparse\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m], reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    209\u001B[0m \u001B[38;5;66;03m# Initialize first layer\u001B[39;00m\n\u001B[0;32m    210\u001B[0m activation \u001B[38;5;241m=\u001B[39m X\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 625\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_n_features(X, reset\u001B[38;5;241m=\u001B[39mreset)\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    411\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    413\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    415\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    416\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    417\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 78400 features, but MLPClassifier is expecting 784 features as input."
     ]
    }
   ],
   "source": [
    "nn_clf.score(test_data_img.reshape(1,-1),test_data_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:05:23.822945400Z",
     "start_time": "2023-11-27T09:05:23.757219500Z"
    }
   },
   "id": "e7f8cf4ffd14805e"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['4'], dtype='<U1')"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_clf.predict(test_data_img[2].reshape(1,-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:05:39.265216200Z",
     "start_time": "2023-11-27T09:05:39.240257900Z"
    }
   },
   "id": "5d9d62235c039724"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(test_data_img[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T09:05:48.676312100Z",
     "start_time": "2023-11-27T09:05:48.639290600Z"
    }
   },
   "id": "efcd1976621350c8"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(f'hello')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T13:41:18.413596900Z",
     "start_time": "2023-11-28T13:41:18.376212600Z"
    }
   },
   "id": "ab80e8da11883091"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "1 11\n",
      "2 12\n",
      "3 13\n"
     ]
    }
   ],
   "source": [
    "test = [10,11,12,13]\n",
    "\n",
    "for i,j in enumerate(test):\n",
    "    print(i,j)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:26:20.892837800Z",
     "start_time": "2023-11-28T15:26:20.853232800Z"
    }
   },
   "id": "4742b3972a7b0f5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "67e9f50aba7f40ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
